# Using enhenced BiDAF++ on QUAC

## Descriptions
An original BiDAF++ model uses Char-CNN for character embedding and GLoVe for word embedding. It is also equipped with contextualized embeddings and self attention. In this model, marker embeddings corresponding to previous answer words are used, while question turn numbers are encoded into question embeddings.

## Architecture of enhenced BiDAF++
<p align="center">
    <img src="Arch.png" width="600"/>
</p>
### Embedding layers from BiDAF++

We aimed to apply ELMo or BERT embedding to the original embeddings.


Let ELMo<sub>k</sub> be a ELMo vector, x<sub>k</sub> denote a original embedding vector and h<sub>k</sub> present a contextual vector generated by bi-LSTM layer. Then we can use ELMo enhanced representation [x<sub>k</sub>; ELMo<sub>k</sub>] instead of x<sub>k</sub>. Also replace h<sub>k</sub> with [h<sub>k</sub>; ELMo<sub>k</sub>].
We do t
### Self-Attention layers from BiDAF++

First, the input is passed through a linear layer with ReLU activations. Then, it passes through a bi-directional GRU or LSTM. After that, we apply attention mechanism between the context and itself as following:

Let h<sub>i</sub>, h<sub>j</sub> be the vectors for context word i and word j and nc be the lengths of the context. Then compute attention between the two words as:
<p align="center">
    <img src="1.png" width="400"/>
</p>

where w<sub>1</sub>,w<sub>2</sub>, and w<sub>3</sub> are learned vectors and ⊙ is element-wise multiplica- tion. In this case, we set a<sub>ij</sub> = −inf if i = j. Then, compute an attended vector c<sub>i</sub> for each context token as:
<p align="center">
    <img src="2.png" width="350"/>
</p>

Compute a context-to-context vector t<sub>c</sub>:
<p align="center">
    <img src="3.png" width="450"/>
</p>

The output of this layer is built concatenating h<sub>i</sub>, c<sub>i</sub>, h<sub>i</sub> ⊙ c<sub>i</sub> and t<sub>c</sub> ⊙ c<sub>i</sub>,
additionally summed with the input before ReLU.
## Prerequisites

## Usage
## Dataset
## Learning curve on training and validation datasets
<p align="center">
    <img src="learning_curve.png" width="150%"/>
</p>


